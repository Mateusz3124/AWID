{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671a349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `~/Desktop/juliaProject/main/notebook`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9726549",
   "metadata": {},
   "source": [
    "Running single threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5174890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, time: 26.985613509, Loss: 0.5697293, Accuracy: 0.69465, LossTest: 0.4165767, AccuracyTest: 0.8122\n",
      "Epoch: 2, time: 10.925329537, Loss: 0.35401136, Accuracy: 0.84615, LossTest: 0.33655655, AccuracyTest: 0.8528\n",
      "Epoch: 3, time: 10.884208945, Loss: 0.26947704, Accuracy: 0.891125, LossTest: 0.31812206, AccuracyTest: 0.8613\n",
      "Epoch: 4, time: 10.862917571, Loss: 0.20914106, Accuracy: 0.921125, LossTest: 0.3164333, AccuracyTest: 0.8663\n",
      "Epoch: 5, time: 10.830551286, Loss: 0.15533797, Accuracy: 0.94715, LossTest: 0.33569756, AccuracyTest: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.main"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "module main\n",
    "using JLD2\n",
    "using net\n",
    "\n",
    "@load \"../../data/imdb_dataset_prepared_embedings.jld2\" X_train y_train X_test y_test embeddings vocab\n",
    "\n",
    "X_train = Int32.(X_train)\n",
    "y_train = Float32.(vec(y_train))\n",
    "X_test = Int32.(X_test)\n",
    "y_test = Float32.(vec(y_test))\n",
    "\n",
    "chain = Chain(\n",
    "    Embedding(embeddings),\n",
    "    Convolution(3, size(embeddings, 1), 8, relu),\n",
    "    MaxPool(8),\n",
    "    Flatten(),\n",
    "    Dense(128, 1, σ),\n",
    "    Classification(binarycrossentropy)\n",
    ")\n",
    "\n",
    "\n",
    "startNetwork(X_train, y_train, X_test, y_test, chain, 64, 5)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec90f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (43.047512s) \tTrain: (l: 0.544829, a: 0.717775) \tTest: (l: 0.398000, a: 0.827000)\n",
      "Epoch: 2 (16.322143s) \tTrain: (l: 0.334099, a: 0.858250) \tTest: (l: 0.335723, a: 0.857800)\n",
      "Epoch: 3 (14.682731s) \tTrain: (l: 0.255252, a: 0.897750) \tTest: (l: 0.323455, a: 0.864200)\n",
      "Epoch: 4 (15.670740s) \tTrain: (l: 0.195805, a: 0.928000) \tTest: (l: 0.324911, a: 0.869000)\n",
      "Epoch: 5 (14.648823s) \tTrain: (l: 0.142523, a: 0.952850) \tTest: (l: 0.342031, a: 0.868400)\n"
     ]
    }
   ],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"X_train\")\n",
    "y_train = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"y_train\")\n",
    "X_test = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"X_test\")\n",
    "y_test = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"y_test\")\n",
    "embeddings = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"embeddings\")\n",
    "vocab = load(\"../../data/imdb_dataset_prepared_embedings.jld2\", \"vocab\")\n",
    "\n",
    "embedding_dim = size(embeddings, 1)\n",
    "\n",
    "using Flux\n",
    "using Printf, Statistics\n",
    "\n",
    "model = Chain(\n",
    "    Flux.Embedding(12849, embedding_dim),\n",
    "    x -> permutedims(x, (2, 1, 3)),\n",
    "    Conv((3,), embedding_dim => 8, relu),\n",
    "    MaxPool((8,)),\n",
    "    Flux.flatten,\n",
    "    Dense(128, 1, σ)\n",
    ")\n",
    "\n",
    "model.layers[1].weight .= embeddings;\n",
    "\n",
    "\n",
    "loss(m, x, y) = Flux.Losses.binarycrossentropy(m(x), y)\n",
    "accuracy(m, x, y) = mean((m(x) .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "dataset = Flux.DataLoader((X_train, y_train), batchsize=64, shuffle=true)\n",
    "\n",
    "opt = Optimisers.setup(Adam(), model)\n",
    "epochs = 5\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in dataset\n",
    "            grads = Flux.gradient(model) do m\n",
    "                loss(m, x, y)\n",
    "            end\n",
    "            Optimisers.update!(opt, model, grads[1])\n",
    "            total_loss += loss(model, x, y)\n",
    "            total_acc += accuracy(model, x, y)\n",
    "            num_samples += 1\n",
    "        end\n",
    "\n",
    "        train_loss = total_loss / num_samples\n",
    "        train_acc = total_acc / num_samples\n",
    "\n",
    "        test_acc = accuracy(model, X_test, y_test)\n",
    "        test_loss = loss(model, X_test, y_test)\n",
    "    end\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%fs) \\tTrain: (l: %f, a: %f) \\tTest: (l: %f, a: %f)\",\n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
